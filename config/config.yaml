##############################################
# RAG System Configuration File
##############################################

# System-wide settings
system:
  log_level: INFO
  request_id_header: X-Request-ID
  environment: development

# Security settings
security:
  api_keys:
    - name: default
      key: "${API_KEY}"
      roles:
        - user
    - name: admin
      key: "${ADMIN_API_KEY}"
      roles:
        - user
        - admin
  rate_limiting:
    enabled: true
    provider: local
    requests: 100
    period_seconds: 60

# Cache settings
cache:
  enabled: true
  provider: local
  default_ttl_seconds: 3600
  max_size: 10000
  cleanup_interval_seconds: 300

# Ingestion API settings
ingestion:
  port: 8000
  host: 0.0.0.0
  workers: 4
  parsers:
    default_parser: vision_parser
    vision_parser:
      enabled: true
      model: gemini-1.5-pro-vision
      # project_id and location loaded directly from environment variables
    simple_text:
      enabled: true
    pymupdf:
      enabled: false
  chunking:
    strategy: page_based
    # Options for page-based chunking
    min_chunk_size: 100
    use_headers_fallback: true
    # Keep fixed size options for backwards compatibility
    chunk_size: 1000
    chunk_overlap: 200
  embedding:
    # Switch between "vertex_ai", "vertex", "openai", "sentence_transformer"
    provider: vertex_ai
    # Vertex AI settings - model only
    # project_id and location loaded directly from environment variables
    model: text-embedding-004
    batch_size: 100
    max_workers: 4
  vector_store:
    # Choose vector store type: "faiss", "pgvector", or "chromadb"
    type: pgvector
    # Common settings
    dimension: 768  # Must match embedding model dimension (768 for text-embedding-004)
    
    # PgVector specific settings
    pgvector:
      connection_string: "postgresql://rushabhsmacbook@localhost:5432/rag_vector_db?sslmode=prefer"
      table_name: "document_embeddings"
      schema_name: "public"
      index_method: "hnsw"  # Options: ivfflat, hnsw
      metadata_path: "./data/pgvector_metadata.pkl"

# Chatbot API settings
chatbot:
  port: 8001
  host: 0.0.0.0
  workers: 4
  retrieval:
    vector_store:
      type: pgvector
      connection_string: "postgresql://rushabhsmacbook@localhost:5432/rag_vector_db?sslmode=prefer"
      table_name: "document_embeddings"
      schema_name: "public"
      dimension: 768
      index_method: "hnsw"
      metadata_path: "./data/pgvector_metadata.pkl"
    embedding:
      provider: vertex_ai
      model: text-embedding-004
      batch_size: 100
    top_k: 10
    similarity_threshold: 0.7
  reranking:
    enabled: true
    type: custom  # Options: custom, cross_encoder
    model_name: cross-encoder/ms-marco-MiniLM-L-6-v2  # Only used for cross_encoder type
    top_k: 3
    score_threshold: 0.5
    # Custom reranker weights
    keyword_weight: 0.3
    tfidf_weight: 0.4
    length_weight: 0.2
    position_weight: 0.1
    min_score_threshold: 0.0
  generation:
    # Switch between "vertex", "anthropic_vertex", "openai", "azure_openai", "groq"
    provider: vertex
    # Vertex AI settings - model only
    # project_id and location loaded directly from environment variables
    model_name: gemini-1.5-pro-002
    temperature: 0.2
    max_tokens: 2048
    top_p: 0.95
    templates_dir: config/prompts/chatbot
    template: rag_prompt.jinja2
  memory:
    # Memory type: "simple" or "langgraph_checkpoint"
    type: langgraph_checkpoint
    # Memory enable/disable settings
    enabled: true
    chat_history_enabled: true
    max_history_days: 30  # Number of days to keep chat history (0 = unlimited)
    # LangGraph memory settings
    store_type: postgres  # "in_memory" or "postgres"
    max_history: 20
    # PostgreSQL settings (only used if store_type is "postgres")
    postgres:
      connection_string: "postgresql://rushabhsmacbook@localhost:5432/langgraph_memory_db?sslmode=prefer"
      pool_min_size: 1
      pool_max_size: 10
      command_timeout: 60
      ssl:
        mode: prefer  # Options: disable, allow, prefer, require, verify-ca, verify-full
        # cert_file: "/path/to/client-cert.pem"  # Uncomment and set path if using client certificates
        # key_file: "/path/to/client-key.pem"
        # ca_file: "/path/to/ca-cert.pem"

# Vision model configuration
vision:
  provider: vertex_ai
  config:
    model: gemini-1.5-pro-002
    # project_id loaded from environment variable PROJECT_ID
