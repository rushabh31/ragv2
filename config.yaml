##############################################
# RAG System Configuration File
##############################################

# System-wide settings
system:
  log_level: INFO
  request_id_header: X-Request-ID
  environment: development

# Security settings
security:
  api_keys:
    - name: default
      key: "${API_KEY}"
      roles:
        - user
    - name: admin
      key: "${ADMIN_API_KEY}"
      roles:
        - user
        - admin
  rate_limiting:
    enabled: true
    provider: local
    requests: 100
    period_seconds: 60

# Cache settings
cache:
  enabled: true
  provider: local
  default_ttl_seconds: 3600
  max_size: 10000
  cleanup_interval_seconds: 300

# Vision model configuration (used by vision_parser)
vision:
  # Choose from: vertex_ai, groq (more providers can be added)
  provider: vertex_ai
  config:
    model: gemini-1.5-pro-002
    region: us-central1

# Ingestion API settings
ingestion:
  port: 8000
  host: 0.0.0.0
  workers: 4
  parsing:
    default_parser: vision_parser
    vision:
      enabled: true
      model: gemini-1.5-pro-002
      max_pages: 100
      max_concurrent_pages: 5  # Number of pages to process in parallel
  chunking:
    strategy: fixed_size
    chunk_size: 1000
    chunk_overlap: 200
  embedding:
    # Choose from: vertex_ai, openai_universal, azure_openai, sentence_transformer, vertex (legacy), openai (legacy)
    provider: vertex_ai
    config:
      model: text-embedding-004
      batch_size: 100
  vector_store:
    type: faiss
    path: ./data/vector_store
    index_params:
      dimension: 768
      metric: inner_product
      nlist: 100
      nprobe: 10

# Chatbot API settings
chatbot:
  port: 8001
  host: 0.0.0.0
  workers: 4
  retrieval:
    vector_store:
      type: faiss
      path: ./data/vector_store
    top_k: 5
    similarity_threshold: 0.7
  reranking:
    enabled: true
    model_name: cross-encoder/ms-marco-MiniLM-L-6-v2
    top_k: 3
    score_threshold: 0.5
  generation:
    # Choose from: vertex, anthropic_vertex, openai, azure_openai, groq
    provider: vertex
    config:
      model_name: gemini-1.5-pro-002
      temperature: 0.2
      max_tokens: 1024
      top_p: 0.95
      prompt_template: ./templates/rag_prompt.jinja2
  memory:
    type: simple
    max_messages: 20
    message_expiry_minutes: 60
    max_sessions: 1000
