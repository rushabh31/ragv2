##############################################
# RAG System Configuration File
##############################################

# System-wide settings
system:
  log_level: INFO
  request_id_header: X-Request-ID
  environment: development

# Security settings
security:
  api_keys:
    - name: default
      key: "${API_KEY}"
      roles:
        - user
    - name: admin
      key: "${ADMIN_API_KEY}"
      roles:
        - user
        - admin
  rate_limiting:
    enabled: true
    provider: local
    requests: 100
    period_seconds: 60

# Cache settings
cache:
  enabled: true
  provider: local
  default_ttl_seconds: 3600
  max_size: 10000
  cleanup_interval_seconds: 300

# Ingestion API settings
ingestion:
  port: 8000
  host: 0.0.0.0
  workers: 4
  parsing:
    default_parser: vertex
    vision:
      enabled: true
      model: gemini-pro-vision
      project_id: "${GCP_PROJECT_ID}"
      location: us-central1
  chunking:
    strategy: fixed_size
    chunk_size: 1000
    chunk_overlap: 200
  embedding:
    # Switch between "vertex" and "sentence_transformer"
    provider: vertex
    # Vertex AI settings
    project_id: "${GCP_PROJECT_ID}"
    location: us-central1
    model: textembedding-gecko
    # Sentence Transformer settings
    model_name: all-MiniLM-L6-v2
    batch_size: 32
    max_workers: 1
  vector_store:
    type: faiss
    path: ./data/vector_store
    index_params:
      dimension: 768
      metric: inner_product
      nlist: 100
      nprobe: 10

# Chatbot API settings
chatbot:
  port: 8001
  host: 0.0.0.0
  workers: 4
  retrieval:
    vector_store:
      type: faiss
      path: ./data/vector_store
    top_k: 5
    similarity_threshold: 0.7
  reranking:
    enabled: true
    model_name: cross-encoder/ms-marco-MiniLM-L-6-v2
    top_k: 3
    score_threshold: 0.5
  generation:
    # Switch between "vertex" and "groq"
    provider: vertex
    # Vertex AI settings
    project_id: "${GCP_PROJECT_ID}"
    location: us-central1
    model: gemini-1.0-pro
    temperature: 0.2
    max_output_tokens: 1024
    top_p: 0.95
    # Groq settings
    api_key: "${GROQ_API_KEY}"
    model: llama3-70b-8192
    templates_dir: templates
    template: rag_prompt.jinja2
  memory:
    type: simple
    max_messages: 20
    message_expiry_minutes: 60
    max_sessions: 1000
